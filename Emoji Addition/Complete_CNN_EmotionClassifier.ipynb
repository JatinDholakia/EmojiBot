{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Amit_EMOTIONS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rsdEEzgEcZCL","colab_type":"text"},"source":["CODE FOR EMOTION CLASSIFIER AND EMOJI ADDITION\n"]},{"cell_type":"markdown","metadata":{"id":"bFAdMEStcibq","colab_type":"text"},"source":["1. DATA PRE-PROCESSING FOR TRAINING EMOTION CLASSIFIER\n"]},{"cell_type":"code","metadata":{"id":"5ajV2o68coLe","colab_type":"code","outputId":"356ff95b-f6b4-416a-c085-83a306b837dc","executionInfo":{"status":"ok","timestamp":1572708762513,"user_tz":-330,"elapsed":17825,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}},"colab":{"base_uri":"https://localhost:8080/","height":846}},"source":["import nltk\n","nltk.download('stopwords')\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from keras.preprocessing.text import Tokenizer\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import random\n","import numpy as np\n","from keras.preprocessing import sequence\n","from keras.utils import np_utils\n","\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation, Lambda\n","from keras.layers.embeddings import Embedding\n","from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n","from keras.preprocessing.text import Tokenizer\n","from collections import defaultdict\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","datapath = '/content/gdrive/Shared drives/NLP/Project_Files/'\n","modelpath = '/content/gdrive/Shared drives/NLP/Project_Files/Models/EmotionClassifier'\n","\n","import pickle as p\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import normalize\n","\n","from bs4 import BeautifulSoup  \n","import re\n","import nltk\n","from nltk.corpus import stopwords \n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import SnowballStemmer, WordNetLemmatizer\n","from nltk import sent_tokenize, word_tokenize, pos_tag\n","\n","\n","#THIS IS THE TRAIN CSV FILE \n","\n","train = pd.read_csv(datapath + 'train.csv')\n","# data = data.dropna()\n","train[:10]\n","\n","#THIS IS THE TEST CSV FILE \n","\n","test = pd.read_csv(datapath + 'test.csv')\n","test[:10]\n","\n","# CHECK DIFFERENT KEYS IN THE CSV\n","test.keys(), train.keys()\n","\n","# PRE-PROCESSING OF TRAIN and TEST DATA\n","\n","del train['conv_id'], train['utterance_idx'], train['speaker_idx'], train['selfeval'], train['tags']\n","del train['Unnamed: 8'], train['Unnamed: 9'], train['Unnamed: 10']\n","train = train.drop_duplicates(subset=('prompt'), keep='first', inplace=False)\n","del train['utterance']\n","del test['conv_id'], test['utterance_idx'], test['speaker_idx'], test['selfeval'], test['tags']\n","test = test.drop_duplicates(subset=('prompt'), keep='first', inplace=False)\n","del test['utterance']\n","\n","\n","# NOW FIND UNIQUE EMOTIONS IN THE DATASET\n","train_unique = []\n","for i in range(len(train)):\n","    if train.iloc[i]['context'] not in train_unique:\n","        train_unique.append(train.iloc[i]['context'])\n","print(train_unique)\n","print(len(train_unique))\n","\n","test_unique = []\n","for i in range(len(train)):\n","    if train.iloc[i]['context'] not in test_unique:\n","        test_unique.append(train.iloc[i]['context'])\n","print(test_unique)\n","print(len(test_unique))\n","train = train.dropna()\n","test=test.dropna()\n","train[:10]\n","test[:10]\n","\n","#STOP WORD PROCESSING, CURRENTLY SET TO FALSE\n","\n","stop_words_en = stopwords.words('english')\n","def cleanText(raw_text, stopwords=False):\n","    '''\n","    Convert a raw review to a cleaned review\n","    '''\n","    text = BeautifulSoup(raw_text, 'html').get_text()  #remove html\n","    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)  # remove non-character\n","    words = letters_only.lower().split() # convert to lower case t\n","\n","    if stopwords:\n","        words = [i for i in words if i not in stop_words_en]\n","    \n","    return( str(\" \".join(words)))\n","\n","cleanTextvec = np.vectorize(cleanText)    \n","filtered_train = train.copy()\n","filtered_test = test.copy()\n","\n","train['prompt'] = cleanTextvec(train['prompt'], False)\n","test['prompt'] = cleanTextvec(test['prompt'], False)\n","\n","\n","# MAKE EMOTION DICTIONARY\n","train['Rating'] = 0\n","test['Rating'] = 0\n","emodict = {'amusement':0, 'satisfaction':1, 'optimism':2, 'pride in achievement':3, 'contentment':4,\n","           'anger':5, 'fear':6, 'disgust':7, 'sadness':8, 'contempt':9}\n","#for i in test_unique:\n","#    print(i, emodict[i])\n","for emotion in emodict:\n","    train['Rating'][train['context']==emotion] = emodict[emotion]\n","    test['Rating'][test['context']==emotion] = emodict[emotion]\n","\n","print(train[train['context'] == train_unique[10]])\n","print(train[train['context'] == train_unique[12]])\n","print(train[train['context'] == train_unique[13]])\n","print(train[train['context'] == train_unique[14]])\n","train = train.drop([4811,6392,7571,61943], axis=0)\n","\n","# ALL PRE-PROCESSING DONE, NOW SAVE IT TO CSV FILE\n","\n","train.to_csv(datapath + 'amit_train_emotion.csv',index=False)# FALSE so that INDEX IS NOT SAVED\n","test.to_csv(datapath + 'amit_test_emotion.csv', index=False)\n","train[:10]\n","test[:10]\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (4,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n","  interactivity=interactivity, compiler=compiler, result=result)\n"],"name":"stderr"},{"output_type":"stream","text":["['sadness', 'fear', 'pride in achievement', 'optimism', 'contentment', 'anger', 'contempt', 'satisfaction', 'disgust', 'amusement', \"oh no. o'm sorry to here that.\", nan, 'Did you call the police?', '296', \"I don't blame you. I don't know anything about Horses_comma_ but congrats on winning the bet\"]\n","15\n","['sadness', 'fear', 'pride in achievement', 'optimism', 'contentment', 'anger', 'contempt', 'satisfaction', 'disgust', 'amusement', \"oh no. o'm sorry to here that.\", nan, 'Did you call the police?', '296', \"I don't blame you. I don't know anything about Horses_comma_ but congrats on winning the bet\"]\n","15\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:125: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:126: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"},{"output_type":"stream","text":["                             context prompt  Rating\n","4811  oh no. o'm sorry to here that.              0\n","                       context prompt  Rating\n","6392  Did you call the police?              0\n","     context                                             prompt  Rating\n","7571     296  yes people and pets too soon so it definitely ...       0\n","                                                 context prompt  Rating\n","61943  I don't blame you. I don't know anything about...              0\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>context</th>\n","      <th>prompt</th>\n","      <th>Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>disgust</td>\n","      <td>i felt guilty when i was driving home one nigh...</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>contentment</td>\n","      <td>my mother stopped by my house one day and said...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>contempt</td>\n","      <td>i just broke up with my girlfriend comma we we...</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>amusement</td>\n","      <td>i received concert tickets for christmas</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>sadness</td>\n","      <td>i ve read an article about a little newborn ba...</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>contentment</td>\n","      <td>my friend s baby hurt himself yesterday i was ...</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>optimism</td>\n","      <td>i really hope my husband finds a full time job...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>anger</td>\n","      <td>some guys shot my neighbour and ran into the w...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>contentment</td>\n","      <td>i m going to see my parents soon</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>anger</td>\n","      <td>i felt very angry when a co worker of mine pre...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        context                                             prompt  Rating\n","0       disgust  i felt guilty when i was driving home one nigh...       7\n","5   contentment  my mother stopped by my house one day and said...       4\n","9      contempt  i just broke up with my girlfriend comma we we...       9\n","13    amusement           i received concert tickets for christmas       0\n","17      sadness  i ve read an article about a little newborn ba...       8\n","22  contentment  my friend s baby hurt himself yesterday i was ...       4\n","27     optimism  i really hope my husband finds a full time job...       2\n","32        anger  some guys shot my neighbour and ran into the w...       5\n","36  contentment                   i m going to see my parents soon       4\n","40        anger  i felt very angry when a co worker of mine pre...       5"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"qOpB_UdDhue6","colab_type":"text"},"source":["2. LOAD PRE-PROCESS DATASETs"]},{"cell_type":"code","metadata":{"id":"EFXy2Fw0hz1O","colab_type":"code","outputId":"b006db6d-fa55-4af9-bea8-184a0a2e797c","executionInfo":{"status":"ok","timestamp":1572708789834,"user_tz":-330,"elapsed":953,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from keras.preprocessing.text import Tokenizer\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import random\n","import numpy as np\n","from keras.preprocessing import sequence\n","from keras.utils import np_utils\n","\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation, Lambda\n","from keras.layers.embeddings import Embedding\n","from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n","from keras.preprocessing.text import Tokenizer\n","from collections import defaultdict\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","datapath = '/content/gdrive/Shared drives/NLP/Project_Files/'\n","modelpath = '/content/gdrive/Shared drives/NLP/Project_Files/Models/EmotionClassifier'\n","\n","import pickle as p\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import normalize\n","\n","from bs4 import BeautifulSoup  \n","import re\n","import nltk\n","from nltk.corpus import stopwords \n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import SnowballStemmer, WordNetLemmatizer\n","from nltk import sent_tokenize, word_tokenize, pos_tag\n","\n","# LOAD CSV FILES\n","train = pd.read_csv(datapath + 'amit_train_emotion.csv')\n","test = pd.read_csv(datapath + 'amit_test_emotion.csv')\n","train = train.dropna()\n","test=test.dropna()\n","#train.set_index('Unnamed: 0')\n","#test.set_index('Unnamed: 0')\n","\n","# NOW MAKE IT READY FOR TRAINING\n","del train['context'], test['context']\n","# train, test = train_test_split(data, test_size = 0.2, random_state = 42)\n","train, val = train_test_split(train, test_size = 0.1, random_state = 42)\n","y_train = np.array(train['Rating'])\n","y_val = np.array(val['Rating'])\n","y_test = np.array(test['Rating'])\n","\n","# CHECK NUMBER OF TRAIN, VALIDATION AND TEST \n","print(train.shape)\n","print(val.shape)\n","print(test.shape)\n","\n","max_features = 20000\n","EMBEDDING_DIM = 100\n","VALIDATION_SPLIT = 0.2\n","maxlen = 1000\n","batch_size = 128\n","nb_classes = 10\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","(16317, 2)\n","(1814, 2)\n","(2492, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yrFL8y1F5_JQ","colab_type":"code","outputId":"59803b96-438e-4929-e737-64e37b0c6715","executionInfo":{"status":"ok","timestamp":1572548074119,"user_tz":-330,"elapsed":1563,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["train = pd.read_csv(datapath + 'amit_train_emotion.csv')\n","test = pd.read_csv(datapath + 'amit_test_emotion.csv')\n","train = train.dropna()\n","test=test.dropna()\n","\n","val=pd.read_csv(datapath + 'akhilesh_val_emotion.csv')\n","y_train = np.array(train['Rating'])\n","y_val = np.array(val['Rating'])\n","y_test = np.array(test['Rating'])\n","print(train.shape)\n","print(val.shape)\n","print(test.shape)\n","\n","max_features = 20000\n","EMBEDDING_DIM = 100\n","VALIDATION_SPLIT = 0.2\n","maxlen = 1000\n","batch_size = 128\n","nb_classes = 10"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(18131, 3)\n","(1814, 2)\n","(2492, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_c2AqONhhYIl","colab_type":"text"},"source":["3. FITTING TOKENIZER\n"]},{"cell_type":"code","metadata":{"id":"-5sLChVOhcGi","colab_type":"code","outputId":"2b4facc6-a256-43d3-bb65-5c639d5d8e2e","executionInfo":{"status":"ok","timestamp":1572548086795,"user_tz":-330,"elapsed":2270,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["\n","tokenizer = Tokenizer(nb_words=max_features)\n","tokenizer.fit_on_texts(test['prompt'])\n","f = open(datapath + 'amit_normal_tokenizer_prompts.dat', 'wb')\n","p.dump(tokenizer, f)\n","f.close()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n","  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"t-YHdSXuhiS1","colab_type":"text"},"source":["4. LOAD TOKENIZER\n"]},{"cell_type":"code","metadata":{"id":"D4yPqhxJhkun","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"fa37e858-8691-45bb-f7fa-13aa26907c18","executionInfo":{"status":"ok","timestamp":1572708801485,"user_tz":-330,"elapsed":943,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}}},"source":["from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from keras.preprocessing.text import Tokenizer\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import random\n","import numpy as np\n","from keras.preprocessing import sequence\n","from keras.utils import np_utils\n","\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation, Lambda\n","from keras.layers.embeddings import Embedding\n","from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n","from keras.preprocessing.text import Tokenizer\n","from collections import defaultdict\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","datapath = '/content/gdrive/Shared drives/NLP/Project_Files/'\n","modelpath = '/content/gdrive/Shared drives/NLP/Project_Files/Models/EmotionClassifier'\n","\n","import pickle as p\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import normalize\n","\n","from bs4 import BeautifulSoup  \n","import re\n","import nltk\n","from nltk.corpus import stopwords \n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import SnowballStemmer, WordNetLemmatizer\n","from nltk import sent_tokenize, word_tokenize, pos_tag\n","\n","f = open(datapath + 'amit_normal_tokenizer_prompts.dat', 'rb')\n","tokenizer=p.load(f)\n","f.close()\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DKaQOPFFi_xW","colab_type":"text"},"source":["5. TOKENIZATION \n"]},{"cell_type":"code","metadata":{"id":"un15La31jGnY","colab_type":"code","outputId":"1f4250e4-6df1-4bb8-bea1-68f522b9496a","executionInfo":{"status":"ok","timestamp":1572708811416,"user_tz":-330,"elapsed":1325,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["# vectorize the text samples into a 2D integer tensor\n","\n","sequences_train = tokenizer.texts_to_sequences(train['prompt'])\n","sequences_val = tokenizer.texts_to_sequences(val['prompt'])\n","sequences_test = tokenizer.texts_to_sequences(test['prompt'])\n","\n","\n","print('Pad sequences (samples x time)')\n","X_train = sequence.pad_sequences(sequences_train, maxlen=maxlen)\n","X_val = sequence.pad_sequences(sequences_val, maxlen=maxlen)\n","X_test = sequence.pad_sequences(sequences_test, maxlen=maxlen)\n","\n","\n","Y_train = np_utils.to_categorical(y_train, nb_classes)\n","Y_val = np_utils.to_categorical(y_val, nb_classes)\n","Y_test = np_utils.to_categorical(y_test, nb_classes)\n","\n","\n","print('X_train shape:', X_train.shape)\n","print('X_train shape:', X_val.shape)\n","print('X_test shape:', X_test.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Pad sequences (samples x time)\n","X_train shape: (16317, 1000)\n","X_train shape: (1814, 1000)\n","X_test shape: (2492, 1000)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pqYef19PLWcz","colab_type":"text"},"source":["CNN Model Defination\n"]},{"cell_type":"code","metadata":{"id":"S027li9NLYEk","colab_type":"code","outputId":"3ba31b79-e792-4187-a03a-7d54b56214bf","executionInfo":{"status":"ok","timestamp":1572708815439,"user_tz":-330,"elapsed":938,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}},"colab":{"base_uri":"https://localhost:8080/","height":810}},"source":["from keras.layers.convolutional import Convolution1D\n","from keras import backend as K\n","from keras.models import load_model\n","from keras.callbacks import ModelCheckpoint\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","def max_1d(X):\n","    return K.max(X, axis=1)\n","\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers import SpatialDropout1D\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers import SpatialDropout1D\n","from keras.models import Model\n","from keras.layers import Input,Flatten, Dense, Embedding, RNN, Conv1D, BatchNormalization, MaxPooling1D, Activation, Dropout, concatenate, Lambda\n","from keras import optimizers\n","\n","\n","nb_filter = 300\n","filter_length = 3\n","hidden_dims = 300 # 250\n","nb_epoch = 2\n","\n","\n","# nb_filter *= 2\n","\n","print('Build model...')\n","cmodel1 = Sequential()\n","cmodel1.add(Embedding(max_features, 1000))\n","cmodel1.add(SpatialDropout1D(0.2))\n","# we add a Convolution1D, which will learn nb_filter\n","# word group filters of size filter_length:\n","cmodel1.add(Convolution1D(nb_filter=nb_filter,\n","                       filter_length=filter_length,\n","                       border_mode='valid',\n","                       activation='tanh',\n","                       subsample_length=1))\n","\n","#cmodel1.add(BatchNormalization())\n","from keras import optimizers\n","def max_1d(X):\n","    return K.max(X, axis=1)\n","\n","cmodel1.add(Lambda(max_1d, output_shape=(nb_filter,)))\n","cmodel1.add(Dense(hidden_dims))\n","cmodel1.add(Dropout(0.2))\n","cmodel1.add(Activation('relu'))\n","cmodel1.add(Dense(nb_classes))\n","cmodel1.add(Activation('sigmoid'))\n","adam = optimizers.Adam(lr=0.001, decay=1e-6)\n","cmodel1.compile(loss='binary_crossentropy',\n","             optimizer=adam,\n","             metrics=['accuracy'])\n","\n","\n","cmodel1.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Build model...\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, None, 1000)        20000000  \n","_________________________________________________________________\n","spatial_dropout1d_1 (Spatial (None, None, 1000)        0         \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, None, 300)         900300    \n","_________________________________________________________________\n","lambda_1 (Lambda)            (None, 300)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 300)               90300     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 300)               0         \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 300)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                3010      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 20,993,610\n","Trainable params: 20,993,610\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"tanh\", filters=300, kernel_size=3, strides=1, padding=\"valid\")`\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"LO_HTNW5L9qU","colab_type":"text"},"source":["CNN MODEL TRAINING\n"]},{"cell_type":"code","metadata":{"id":"psnf9gBVL_ij","colab_type":"code","outputId":"5b47f8e3-5f49-493c-ffbd-8e8855136793","executionInfo":{"status":"ok","timestamp":1572708970016,"user_tz":-330,"elapsed":146215,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}},"colab":{"base_uri":"https://localhost:8080/","height":474}},"source":["print('Train...')\n","cmodel1.fit(X_train, Y_train, batch_size=batch_size, epochs=2,\n","         validation_data=(X_val, Y_val))\n","score, acc = cmodel1.evaluate(X_test, Y_test,\n","                           batch_size=batch_size)\n","print('Test score:', score)\n","print('Test accuracy:', acc)\n","from keras.models import model_from_json\n","model_json = cmodel1.to_json()\n","with open(datapath+\"AMIT_epoch2W.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","cmodel1.save_weights(datapath+\"AMIT_epoch2W.h5\")\n","print(\"Saved model to disk\")\n"," \n"," "],"execution_count":7,"outputs":[{"output_type":"stream","text":["Train...\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 16317 samples, validate on 1814 samples\n","Epoch 1/2\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","16317/16317 [==============================] - 74s 5ms/step - loss: 0.2974 - acc: 0.9034 - val_loss: 0.2095 - val_acc: 0.9262\n","Epoch 2/2\n","16317/16317 [==============================] - 68s 4ms/step - loss: 0.1809 - acc: 0.9346 - val_loss: 0.1839 - val_acc: 0.9332\n","2492/2492 [==============================] - 3s 1ms/step\n","Test score: 0.19212143517803418\n","Test accuracy: 0.9312600179621725\n","Saved model to disk\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2_8gIheOrohT","colab_type":"text"},"source":["LOAD MODEL"]},{"cell_type":"code","metadata":{"id":"XbHk8aozOxJo","colab_type":"code","outputId":"384104d2-62c7-4364-ccfe-1fa57f3d2e35","executionInfo":{"status":"ok","timestamp":1572709159401,"user_tz":-330,"elapsed":2599,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# later...\n"," from keras.models import model_from_json\n","# load json and create model\n","json_file = open(datapath+\"AMIT_epoch2W.json\", 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(datapath+\"AMIT_epoch2W.h5\")\n","print(\"Loaded model from disk\")\n"," \n","\n","\n","\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Loaded model from disk\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9rESKx3kR0cH","colab_type":"text"},"source":["MICRO ACCURACY\n"]},{"cell_type":"code","metadata":{"id":"QauCnzSqf_oE","colab_type":"code","outputId":"d03cce94-fb85-403d-cfc4-e1a971d5e3c0","executionInfo":{"status":"ok","timestamp":1572709170297,"user_tz":-330,"elapsed":8190,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["val_preds = loaded_model.predict_classes(X_val, verbose=0)\n","preds = loaded_model.predict_classes(X_test, verbose=0)\n","print('Validation micro accuracy: ', accuracy_score(val['Rating'], val_preds) * 100)\n","print('Test micro accuracy: ', accuracy_score(test['Rating'], preds) * 100)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Validation micro accuracy:  61.852260198456456\n","Test micro accuracy:  60.63402889245586\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1uS3XCywR3Nr","colab_type":"text"},"source":["MACRO ACCURACY"]},{"cell_type":"code","metadata":{"id":"y2wm_uIvR5GZ","colab_type":"code","outputId":"53ac4765-5f20-4f50-b0b5-a0338988e705","executionInfo":{"status":"ok","timestamp":1572709189991,"user_tz":-330,"elapsed":967,"user":{"displayName":"AMIT KUMAR SINGH YADAV 16110011","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCMPSrHNycM7XLdv8Kb4VcOUb095RZwOmBm576XzA=s64","userId":"08243289629062170512"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["s = 0\n","for i in range(10):\n","    s += accuracy_score(val[val['Rating']==i]['Rating'], val_preds[val['Rating']==i])\n","print('Validation macro accuracy:',s * 10)\n","\n","s = 0\n","for i in range(10):\n","    s += accuracy_score(test[test['Rating']==i]['Rating'], preds[test['Rating']==i])\n","print('Test macro accuracy:',s * 10)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Validation macro accuracy: 59.91902290550014\n","Test macro accuracy: 58.26756187664914\n"],"name":"stdout"}]}]}